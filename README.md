# DDPG_env_IEEE30_XDU
这是一个为基于DDPG算法的IEEE30模型仿真的训练集的维护项目

## 1. 项目结构介绍（更新中……）
项目核心内容是以下4个文件
### 1.1 ddpg_agent.py - DDPG智能体实现
**开头的常量用于超参数调节**
	创建A网络和C网络，并且能加载和保存经验缓冲区的文件。
### 1.2 ieee30_env.py - IEEE 30节点电力系统环境
负责导入和创建IEEE30的电力系统环境，构建奖励函数
#### 基础约束（硬约束）：

1. 发电机负出力惩罚：严厉惩罚负出力情况（-100000 * |Pg|）
2. 发电成本：二次函数形式，c2 Pg² + c1 Pg + c0
3. 电压质量（电压控制）：
- 电压越限惩罚：惩罚电压超出[0.95, 1.05]范围的情况
- 电压质量奖励：奖励电压接近1.0标幺值的情况
4. 发电均衡（经济性）：

- 发电机出力均衡奖励：基于出力比例标准差，鼓励均衡发电
- 轻载惩罚：惩罚发电机出力低于容量20%的情况
5. 网络状态（安全性）：

- 支路负载均衡奖励：基于负载率标准差，鼓励均衡负载
- 过载惩罚：对超过容量限制的支路进行三次方惩罚
- 系统损耗惩罚：基于支路电阻和电流平方的损耗计算
### 1.3 buffer. py -  经验回放缓冲区的实现
### 1.4 train. py - 训练主程序
**开头的常量用于超参数调节**
用来

***
至于其他可以由项目生成的文件和环境相关文件，就不再上传了（不然每次传个2.5G，啥用没有），下面也简单介绍：

 - analyze_training.py - 训练结果分析工具
	 目前还没啥用，相关功能还没实现
 - offline_learning_demo.py - 离线学习示例
	 一开始的时候拿来和**不使用离线数据的训练集**做结果对比的，只是为了显示**引入离线数据**确实可以加快收敛，小玩具hhhh
 - __pycache__ 目录 - Python编译缓存
 - venv 目录 - 虚拟环境
 - checkpoints 目录 - 模型检查点和经验回放数据
	 每次训练完成后，会分别生成一个训练离线数据和一个经验文件到该文件夹中，每次使用离线数据进行训练时，都会调用该文件夹中的所有数据。by the way，**后期数据清洗和整合可能会用到（？）**
 - result 目录 - 训练结果图片
	 如题
## 2. 有待改进的内容（更新中……）
## 3. 碎碎念
